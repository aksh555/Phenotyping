{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import date,time,datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./mimic-iii\"\n",
    "files_dir = \"./dump_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshara/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "notes = pd.read_csv(os.path.join(data_dir, 'NOTEEVENTS.csv'))\n",
    "patients = pd.read_csv(os.path.join(data_dir, 'PATIENTS.csv'),parse_dates=[3],date_parser=lambda x:datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))\n",
    "diag = pd.read_csv(os.path.join(data_dir, 'DIAGNOSES_ICD.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SEQ_NUM</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1297</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1298</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>2.0</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1299</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1300</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1301</td>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651042</th>\n",
       "      <td>639798</td>\n",
       "      <td>97503</td>\n",
       "      <td>188195</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651043</th>\n",
       "      <td>639799</td>\n",
       "      <td>97503</td>\n",
       "      <td>188195</td>\n",
       "      <td>3.0</td>\n",
       "      <td>V5869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651044</th>\n",
       "      <td>639800</td>\n",
       "      <td>97503</td>\n",
       "      <td>188195</td>\n",
       "      <td>4.0</td>\n",
       "      <td>V1279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651045</th>\n",
       "      <td>639801</td>\n",
       "      <td>97503</td>\n",
       "      <td>188195</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651046</th>\n",
       "      <td>639802</td>\n",
       "      <td>97503</td>\n",
       "      <td>188195</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>651047 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
       "0         1297         109   172335      1.0     40301\n",
       "1         1298         109   172335      2.0       486\n",
       "2         1299         109   172335      3.0     58281\n",
       "3         1300         109   172335      4.0      5855\n",
       "4         1301         109   172335      5.0      4254\n",
       "...        ...         ...      ...      ...       ...\n",
       "651042  639798       97503   188195      2.0     20280\n",
       "651043  639799       97503   188195      3.0     V5869\n",
       "651044  639800       97503   188195      4.0     V1279\n",
       "651045  639801       97503   188195      5.0      5275\n",
       "651046  639802       97503   188195      6.0      5569\n",
       "\n",
       "[651047 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58976"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag['HADM_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag['ICD9_CODE'] = diag.ICD9_CODE.astype(str)\n",
    "diag = diag.drop(['ROW_ID','SEQ_NUM','SUBJECT_ID'],axis = 1)\n",
    "diag = pd.pivot_table(diag,index='HADM_ID',values='ICD9_CODE',aggfunc=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(mlb.fit_transform(diag['ICD9_CODE']),columns=mlb.classes_, index=diag.index)\n",
    "df1.reset_index(level=df1.index.names, inplace=True)\n",
    "df1 = df1.drop('nan', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>0030</th>\n",
       "      <th>0031</th>\n",
       "      <th>0038</th>\n",
       "      <th>0039</th>\n",
       "      <th>0041</th>\n",
       "      <th>0048</th>\n",
       "      <th>0049</th>\n",
       "      <th>0051</th>\n",
       "      <th>00581</th>\n",
       "      <th>...</th>\n",
       "      <th>V8801</th>\n",
       "      <th>V8811</th>\n",
       "      <th>V8812</th>\n",
       "      <th>V8821</th>\n",
       "      <th>V9010</th>\n",
       "      <th>V902</th>\n",
       "      <th>V9039</th>\n",
       "      <th>V9081</th>\n",
       "      <th>V9089</th>\n",
       "      <th>V9103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58971</th>\n",
       "      <td>199993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58972</th>\n",
       "      <td>199994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58973</th>\n",
       "      <td>199995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58974</th>\n",
       "      <td>199998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58975</th>\n",
       "      <td>199999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58976 rows × 6985 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HADM_ID  0030  0031  0038  0039  0041  0048  0049  0051  00581  ...  \\\n",
       "0       100001     0     0     0     0     0     0     0     0      0  ...   \n",
       "1       100003     0     0     0     0     0     0     0     0      0  ...   \n",
       "2       100006     0     0     0     0     0     0     0     0      0  ...   \n",
       "3       100007     0     0     0     0     0     0     0     0      0  ...   \n",
       "4       100009     0     0     0     0     0     0     0     0      0  ...   \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...   \n",
       "58971   199993     0     0     0     0     0     0     0     0      0  ...   \n",
       "58972   199994     0     0     0     0     0     0     0     0      0  ...   \n",
       "58973   199995     0     0     0     0     0     0     0     0      0  ...   \n",
       "58974   199998     0     0     0     0     0     0     0     0      0  ...   \n",
       "58975   199999     0     0     0     0     0     0     0     0      0  ...   \n",
       "\n",
       "       V8801  V8811  V8812  V8821  V9010  V902  V9039  V9081  V9089  V9103  \n",
       "0          0      0      0      0      0     0      0      0      0      0  \n",
       "1          0      0      0      0      0     0      0      0      0      0  \n",
       "2          0      0      0      0      0     0      0      0      0      0  \n",
       "3          0      0      0      0      0     0      0      0      0      0  \n",
       "4          0      0      0      0      0     0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...   ...    ...    ...    ...    ...  \n",
       "58971      0      0      0      0      0     0      0      0      0      0  \n",
       "58972      0      0      0      0      0     0      0      0      0      0  \n",
       "58973      0      0      0      0      0     0      0      0      0      0  \n",
       "58974      0      0      0      0      0     0      0      0      0      0  \n",
       "58975      0      0      0      0      0     0      0      0      0      0  \n",
       "\n",
       "[58976 rows x 6985 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(os.path.join(files_dir, \"hadm_icd.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load hadm-icd file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(os.path.join(files_dir, \"hadm_icd.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df1.sum(axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8844678466,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1444,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 17,\n",
       " 139,\n",
       " 26,\n",
       " 19,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 15,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 16,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 376,\n",
       " 44,\n",
       " 515,\n",
       " 118,\n",
       " 150,\n",
       " 88,\n",
       " 110,\n",
       " 60,\n",
       " 4,\n",
       " 467,\n",
       " 127,\n",
       " 27,\n",
       " 395,\n",
       " 206,\n",
       " 3725,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 10,\n",
       " 25,\n",
       " 2,\n",
       " 26,\n",
       " 37,\n",
       " 81,\n",
       " 4,\n",
       " 614,\n",
       " 4,\n",
       " 144,\n",
       " 58,\n",
       " 703,\n",
       " 239,\n",
       " 293,\n",
       " 13,\n",
       " 473,\n",
       " 967,\n",
       " 191,\n",
       " 39,\n",
       " 213,\n",
       " 404,\n",
       " 12,\n",
       " 10,\n",
       " 52,\n",
       " 300,\n",
       " 204,\n",
       " 71,\n",
       " 19,\n",
       " 538,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 29,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 12,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 46,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 73,\n",
       " 1,\n",
       " 27,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 32,\n",
       " 21,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 27,\n",
       " 114,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 18,\n",
       " 21,\n",
       " 19,\n",
       " 173,\n",
       " 5,\n",
       " 290,\n",
       " 2,\n",
       " 14,\n",
       " 174,\n",
       " 1,\n",
       " 93,\n",
       " 1,\n",
       " 1,\n",
       " 1218,\n",
       " 2,\n",
       " 674,\n",
       " 69,\n",
       " 1,\n",
       " 11,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 91,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 79,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 23,\n",
       " 15,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 37,\n",
       " 39,\n",
       " 23,\n",
       " 28,\n",
       " 1,\n",
       " 12,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 15,\n",
       " 646,\n",
       " 101,\n",
       " 337,\n",
       " 129,\n",
       " 37,\n",
       " 172,\n",
       " 5,\n",
       " 2,\n",
       " 126,\n",
       " 2,\n",
       " 111,\n",
       " 21,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 115,\n",
       " 1,\n",
       " 14,\n",
       " 7,\n",
       " 134,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 11,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 254,\n",
       " 3,\n",
       " 86,\n",
       " 14,\n",
       " 4,\n",
       " 2,\n",
       " 73,\n",
       " 2,\n",
       " 12,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 11,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 21,\n",
       " 59,\n",
       " 90,\n",
       " 28,\n",
       " 98,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 13,\n",
       " 1,\n",
       " 2,\n",
       " 27,\n",
       " 16,\n",
       " 17,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 16,\n",
       " 16,\n",
       " 37,\n",
       " 30,\n",
       " 4,\n",
       " 38,\n",
       " 8,\n",
       " 31,\n",
       " 31,\n",
       " 20,\n",
       " 43,\n",
       " 1,\n",
       " 5,\n",
       " 10,\n",
       " 337,\n",
       " 72,\n",
       " 45,\n",
       " 26,\n",
       " 41,\n",
       " 22,\n",
       " 6,\n",
       " 8,\n",
       " 127,\n",
       " 7,\n",
       " 15,\n",
       " 3,\n",
       " 2,\n",
       " 90,\n",
       " 36,\n",
       " 12,\n",
       " 13,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 11,\n",
       " 11,\n",
       " 5,\n",
       " 73,\n",
       " 335,\n",
       " 35,\n",
       " 167,\n",
       " 391,\n",
       " 175,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 11,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 20,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 14,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 72,\n",
       " 58,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 27,\n",
       " 81,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 302,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 70,\n",
       " 33,\n",
       " 219,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 70,\n",
       " 55,\n",
       " 41,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 37,\n",
       " 48,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 49,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 103,\n",
       " 254,\n",
       " 251,\n",
       " 51,\n",
       " 25,\n",
       " 22,\n",
       " 34,\n",
       " 15,\n",
       " 754,\n",
       " 56,\n",
       " 217,\n",
       " 45,\n",
       " 101,\n",
       " 75,\n",
       " 317,\n",
       " 794,\n",
       " 137,\n",
       " 36,\n",
       " 42,\n",
       " 39,\n",
       " 767,\n",
       " 90,\n",
       " 843,\n",
       " 20,\n",
       " 136,\n",
       " 8,\n",
       " 45,\n",
       " 437,\n",
       " 5,\n",
       " 169,\n",
       " 18,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 28,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 82,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 22,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 23,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 339,\n",
       " 19,\n",
       " 9,\n",
       " 19,\n",
       " 2,\n",
       " 2,\n",
       " 24,\n",
       " 1,\n",
       " 182,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 39,\n",
       " 7,\n",
       " 4,\n",
       " 184,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 195,\n",
       " 30,\n",
       " 13,\n",
       " 65,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 80,\n",
       " 46,\n",
       " 321,\n",
       " 35,\n",
       " 17,\n",
       " 11,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 42,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 10,\n",
       " 2,\n",
       " 17,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 21,\n",
       " 10,\n",
       " 75,\n",
       " 1,\n",
       " 25,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 20,\n",
       " 11,\n",
       " 224,\n",
       " 1,\n",
       " 11,\n",
       " 8,\n",
       " 62,\n",
       " 13,\n",
       " 49,\n",
       " 1,\n",
       " 35,\n",
       " 25,\n",
       " 41,\n",
       " 31,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 18,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 10,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 30,\n",
       " 4,\n",
       " 12,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 17,\n",
       " 5,\n",
       " 113,\n",
       " 4,\n",
       " 120,\n",
       " 210,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 199,\n",
       " 10,\n",
       " 2,\n",
       " 24,\n",
       " 3,\n",
       " 15,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 13,\n",
       " 10,\n",
       " 3,\n",
       " 75,\n",
       " 145,\n",
       " 91,\n",
       " 10,\n",
       " 72,\n",
       " 5,\n",
       " 2,\n",
       " 18,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 110,\n",
       " 6,\n",
       " 12,\n",
       " 203,\n",
       " 76,\n",
       " 10,\n",
       " 20,\n",
       " 27,\n",
       " 4914,\n",
       " 32,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 20,\n",
       " 105,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 9057,\n",
       " 319,\n",
       " 454,\n",
       " 24,\n",
       " 48,\n",
       " 204,\n",
       " 201,\n",
       " 421,\n",
       " 32,\n",
       " 4,\n",
       " 44,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 954,\n",
       " 321,\n",
       " 130,\n",
       " 185,\n",
       " 445,\n",
       " 284,\n",
       " 85,\n",
       " 169,\n",
       " 1138,\n",
       " 425,\n",
       " 198,\n",
       " 265,\n",
       " 121,\n",
       " 33,\n",
       " 31,\n",
       " 19,\n",
       " 447,\n",
       " 90,\n",
       " 115,\n",
       " 59,\n",
       " 19,\n",
       " 2,\n",
       " 71,\n",
       " 8,\n",
       " 1,\n",
       " 34,\n",
       " 122,\n",
       " 18,\n",
       " 9,\n",
       " 186,\n",
       " 1,\n",
       " 10,\n",
       " 101,\n",
       " 47,\n",
       " 8,\n",
       " 12,\n",
       " 26,\n",
       " 2,\n",
       " 11,\n",
       " 5,\n",
       " 75,\n",
       " 1,\n",
       " 3,\n",
       " 89,\n",
       " 505,\n",
       " 21,\n",
       " 12,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 21,\n",
       " 10,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 290,\n",
       " 216,\n",
       " 5,\n",
       " 28,\n",
       " 16,\n",
       " 29,\n",
       " 5,\n",
       " 3,\n",
       " 20,\n",
       " 1,\n",
       " 37,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 204,\n",
       " 61,\n",
       " 136,\n",
       " 35,\n",
       " 24,\n",
       " 1259,\n",
       " 3,\n",
       " 25,\n",
       " 4,\n",
       " 248,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 151,\n",
       " 22,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 20,\n",
       " 6,\n",
       " 3,\n",
       " 25,\n",
       " 45,\n",
       " 2,\n",
       " 5930,\n",
       " 110,\n",
       " 7,\n",
       " 8689,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 18,\n",
       " 3,\n",
       " 4,\n",
       " 78,\n",
       " 26,\n",
       " 28,\n",
       " 10,\n",
       " 139,\n",
       " 12,\n",
       " 123,\n",
       " 21,\n",
       " 99,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 2082,\n",
       " 67,\n",
       " 7,\n",
       " 2,\n",
       " 36,\n",
       " 1,\n",
       " 6,\n",
       " 265,\n",
       " 458,\n",
       " 3,\n",
       " 380,\n",
       " 254,\n",
       " 64,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2272,\n",
       " 3039,\n",
       " 4528,\n",
       " 984,\n",
       " 536,\n",
       " 1348,\n",
       " 332,\n",
       " 1384,\n",
       " 1374,\n",
       " 575,\n",
       " 13,\n",
       " 357,\n",
       " 2167,\n",
       " 1425,\n",
       " 103,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshara/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "notes = pd.read_csv(os.path.join(data_dir, 'NOTEEVENTS.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/akshara/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/akshara/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowBallStemmer = SnowballStemmer(\"english\")\n",
    "exclude = list(nltk.corpus.stopwords.words(\"english\"))\n",
    "exclude.extend(list(string.punctuation))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = re.sub('\\[\\*\\*[^\\]]*\\*\\*\\]', ' ', text)\n",
    "    text = re.sub('<[^>]*>', ' ', text)\n",
    "    text = re.sub('[\\W\\_]+', ' ', text.lower()) \n",
    "    text = re.sub(' \\d+', ' ', text)\n",
    "    return \" \".join([word for word in nltk.tokenize.word_tokenize(text) if word not in exclude])\n",
    "\n",
    "notes['TEXT'] = notes['TEXT'].apply(str)        \n",
    "notes[\"TEXT\"] = notes[\"TEXT\"].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    df.TEXT = df.TEXT.fillna(' ')\n",
    "    df.TEXT = df.TEXT.str.replace('\\n',' ')\n",
    "    df.TEXT = df.TEXT.str.replace('\\r',' ')\n",
    "    df.TEXT = df.TEXT.str.replace(' +', ' ')\n",
    "    return df\n",
    "\n",
    "df_text = preprocess_text(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Discharge summary', 'Echo', 'ECG', 'Nursing', 'Physician ',\n",
       "       'Rehab Services', 'Case Management ', 'Respiratory ', 'Nutrition',\n",
       "       'General', 'Social Work', 'Pharmacy', 'Consult', 'Radiology',\n",
       "       'Nursing/other'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['CATEGORY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_text = notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_rad = df_text[df_text['CATEGORY']=='Radiology']\n",
    "notes_disch = df_text[df_text['CATEGORY']=='Discharge summary']\n",
    "notes_nurse = df_text[df_text['CATEGORY']=='Nursing']\n",
    "notes_gen = df_text[df_text['CATEGORY']=='General']\n",
    "notes_phys = df_text[df_text['CATEGORY']=='Physician ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAD: (45526, 2)\n",
      "NURSE: (9070, 2)\n",
      "DISCH: (52726, 2)\n",
      "PHYS: (8983, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'RAD: {notes_rad.shape}\\nNURSE: {notes_nurse.shape}\\nDISCH: {notes_disch.shape}\\nPHYS: {notes_phys.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45526"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_rad['HADM_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_rad = notes_rad.groupby('HADM_ID')['TEXT'].apply(' '.join).reset_index()\n",
    "notes_disch = notes_disch.groupby('HADM_ID')['TEXT'].apply(' '.join).reset_index()\n",
    "notes_phys = notes_phys.groupby('HADM_ID')['TEXT'].apply(' '.join).reset_index()\n",
    "notes_nurse = notes_nurse.groupby('HADM_ID')['TEXT'].apply(' '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>chief complaint coffee ground emesis light hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100018.0</td>\n",
       "      <td>sicu hpi male w extensive medical history incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100020.0</td>\n",
       "      <td>chief complaint hypotension saw examined patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100037.0</td>\n",
       "      <td>chief complaint hour events received units pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100063.0</td>\n",
       "      <td>chief complaint intoxication seizure hpi hx et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>199909.0</td>\n",
       "      <td>tsicu hpi yom p stairs etoh tx osh imaging sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>199911.0</td>\n",
       "      <td>chief complaint melena coffee ground emesis sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>199940.0</td>\n",
       "      <td>sicu hpi pod7 yom p l fem pt situ svg ef cr wt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>199948.0</td>\n",
       "      <td>chief complaint respiratory distress saw exami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8982</th>\n",
       "      <td>199972.0</td>\n",
       "      <td>cvicu hpi chief complaint pod yom p avr stjude...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8983 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HADM_ID                                               TEXT\n",
       "0     100003.0  chief complaint coffee ground emesis light hea...\n",
       "1     100018.0  sicu hpi male w extensive medical history incl...\n",
       "2     100020.0  chief complaint hypotension saw examined patie...\n",
       "3     100037.0  chief complaint hour events received units pla...\n",
       "4     100063.0  chief complaint intoxication seizure hpi hx et...\n",
       "...        ...                                                ...\n",
       "8978  199909.0  tsicu hpi yom p stairs etoh tx osh imaging sho...\n",
       "8979  199911.0  chief complaint melena coffee ground emesis sa...\n",
       "8980  199940.0  sicu hpi pod7 yom p l fem pt situ svg ef cr wt...\n",
       "8981  199948.0  chief complaint respiratory distress saw exami...\n",
       "8982  199972.0  cvicu hpi chief complaint pod yom p avr stjude...\n",
       "\n",
       "[8983 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_phys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all1 = notes_rad.merge(notes_disch, on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all1['NOTES'] = df_all1['TEXT_x'].map(str) + ' ' + df_all1['TEXT_y'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all1 = df_all1[['HADM_ID', 'NOTES']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>NOTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>59 year old male hcv related cirrhosis grade i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100018.0</td>\n",
       "      <td>impaired physical mobility assessment patient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100020.0</td>\n",
       "      <td>58yom withl progressive ms since baclofen abdo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100037.0</td>\n",
       "      <td>chief complaint pancytopenia ich hpi presented...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100063.0</td>\n",
       "      <td>pt male found lying outside liquor store intox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>199909.0</td>\n",
       "      <td>pt log roll precautions hob degrees remains ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>199911.0</td>\n",
       "      <td>52 yo f history hcv cirrhosis grade varices mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8952</th>\n",
       "      <td>199940.0</td>\n",
       "      <td>demographics attending md r admit diagnosis no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953</th>\n",
       "      <td>199948.0</td>\n",
       "      <td>74 f contributory pmh presented rectal prolaps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8954</th>\n",
       "      <td>199972.0</td>\n",
       "      <td>valve replacement aortic bioprosthetic avr ass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8955 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HADM_ID                                              NOTES\n",
       "0     100003.0  59 year old male hcv related cirrhosis grade i...\n",
       "1     100018.0  impaired physical mobility assessment patient ...\n",
       "2     100020.0  58yom withl progressive ms since baclofen abdo...\n",
       "3     100037.0  chief complaint pancytopenia ich hpi presented...\n",
       "4     100063.0  pt male found lying outside liquor store intox...\n",
       "...        ...                                                ...\n",
       "8950  199909.0  pt log roll precautions hob degrees remains ne...\n",
       "8951  199911.0  52 yo f history hcv cirrhosis grade varices mu...\n",
       "8952  199940.0  demographics attending md r admit diagnosis no...\n",
       "8953  199948.0  74 f contributory pmh presented rectal prolaps...\n",
       "8954  199972.0  valve replacement aortic bioprosthetic avr ass...\n",
       "\n",
       "[8955 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2 = notes_nurse.merge(notes_phys, on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2['NOTES'] = df_all2['TEXT_x'].map(str) + ' ' + df_all2['TEXT_y'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2 = df_all2[['HADM_ID', 'NOTES']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    for j in [xx]:#[notes_rad, notes_disch, notes_nurse, notes_phys]:\n",
    "        print(j.iloc[i].TEXT)\n",
    "        print('\\n')\n",
    "        print(j.iloc[i].TRANS_TEXT)\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_rad.to_csv(os.path.join(files_dir, 'notes_rad.csv'), index=False)\n",
    "notes_disch.to_csv(os.path.join(files_dir, 'notes_disch.csv'), index=False)\n",
    "notes_nurse.to_csv(os.path.join(files_dir, 'notes_nurse.csv'), index=False)\n",
    "notes_phys.to_csv(os.path.join(files_dir, 'notes_phys.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "notes_rad = pd.read_csv(os.path.join(files_dir, 'notes_rad.csv'))\n",
    "notes_disch = pd.read_csv(os.path.join(files_dir, 'notes_disch.csv'))\n",
    "notes_nurse = pd.read_csv(os.path.join(files_dir, 'notes_nurse.csv'))\n",
    "notes_phys = pd.read_csv(os.path.join(files_dir, 'notes_phys.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting googletrans\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "Collecting httpx==0.13.3\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 970 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: certifi in /home/akshara/anaconda3/lib/python3.8/site-packages (from httpx==0.13.3->googletrans) (2020.6.20)\n",
      "Collecting httpcore==0.9.*\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 138 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting hstspreload\n",
      "  Downloading hstspreload-2020.12.22-py3-none-any.whl (994 kB)\n",
      "\u001b[K     |████████████████████████████████| 994 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna==2.* in /home/akshara/anaconda3/lib/python3.8/site-packages (from httpx==0.13.3->googletrans) (2.10)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: chardet==3.* in /home/akshara/anaconda3/lib/python3.8/site-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
      "Collecting rfc3986<2,>=1.3\n",
      "  Downloading rfc3986-1.4.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting h11<0.10,>=0.8\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 3.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting h2==3.*\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 518 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting hpack<4,>=3.0\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15735 sha256=2048085c96a43d37dd21c3002c579e2120642de92f328d486f3dc20d2756dd0c\n",
      "  Stored in directory: /home/akshara/.cache/pip/wheels/0e/ce/9b/d51de1064911d42480ab6b57fc943ee36572441f27546354e2\n",
      "Successfully built googletrans\n",
      "Installing collected packages: sniffio, h11, hyperframe, hpack, h2, httpcore, hstspreload, rfc3986, httpx, googletrans\n",
      "Successfully installed googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.12.22 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.4.0 sniffio-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_rad['TEXT'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting google_trans_new\n",
      "  Downloading google_trans_new-1.1.9-py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: google-trans-new\n",
      "Successfully installed google-trans-new-1.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install google_trans_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_trans_new import google_translator  \n",
    "\n",
    "translator = google_translator()  \n",
    "translate_text = translator.translate('Hola mundo!', lang_src='es', lang_tgt='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World! '"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001.0</td>\n",
       "      <td>chest pa lat clip reason eval infiltrate medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>pm liver gallbladder us single organ clip reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006.0</td>\n",
       "      <td>chest portable ap clip reason please assess in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100009.0</td>\n",
       "      <td>pm chest pa lat clip reason pre op admitting d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100010.0</td>\n",
       "      <td>pm chest portable ap different physician reaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45521</th>\n",
       "      <td>199993.0</td>\n",
       "      <td>chest portable ap clip reason r effusion medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45522</th>\n",
       "      <td>199994.0</td>\n",
       "      <td>pm chest portable ap clip reason pt self extub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45523</th>\n",
       "      <td>199995.0</td>\n",
       "      <td>pm abdomen u complete study duplex dopp abd pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45524</th>\n",
       "      <td>199998.0</td>\n",
       "      <td>pm chest port line placement clip reason line ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45525</th>\n",
       "      <td>199999.0</td>\n",
       "      <td>chest portable ap clip reason interval change ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45526 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HADM_ID                                               TEXT\n",
       "0      100001.0  chest pa lat clip reason eval infiltrate medic...\n",
       "1      100003.0  pm liver gallbladder us single organ clip reas...\n",
       "2      100006.0  chest portable ap clip reason please assess in...\n",
       "3      100009.0  pm chest pa lat clip reason pre op admitting d...\n",
       "4      100010.0  pm chest portable ap different physician reaso...\n",
       "...         ...                                                ...\n",
       "45521  199993.0  chest portable ap clip reason r effusion medic...\n",
       "45522  199994.0  pm chest portable ap clip reason pt self extub...\n",
       "45523  199995.0  pm abdomen u complete study duplex dopp abd pe...\n",
       "45524  199998.0  pm chest port line placement clip reason line ...\n",
       "45525  199999.0  chest portable ap clip reason interval change ...\n",
       "\n",
       "[45526 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(text):\n",
    "    text_ch = text.split('. ')\n",
    "    text_tr = []\n",
    "    for x in text_ch:\n",
    "        x = translator.translate(x, lang_src='en', lang_tgt='es')\n",
    "        x = translator.translate(x, lang_src='es', lang_tgt='en')\n",
    "        text_tr.append(x)\n",
    "    return \". \".join(text_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = notes_phys.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [xx]:#, notes_disch, notes_nurse, notes_rad]:\n",
    "    df['TRANS_TEXT_1'] = df['TEXT'].apply(translator.translate, lang_src='en', lang_tgt='es')\n",
    "    df['TRANS_TEXT'] = df['TRANS_TEXT_1'].apply(translator.translate, lang_src='es', lang_tgt='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-182-46a8156cf769>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRANS_TEXT'] = df.apply(lambda x: trans(x['TEXT']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "for df in [xx]:#, notes_disch, notes_nurse, notes_rad]:\n",
    "    df['TRANS_TEXT'] = df.apply(lambda x: trans(x['TEXT']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rad = notes_rad.merge(df1, how = 'inner',  left_on=\"HADM_ID\", right_on = \"HADM_ID\")\n",
    "df_disch = notes_disch.merge(df1, how = 'inner',  left_on=\"HADM_ID\", right_on = \"HADM_ID\")\n",
    "df_nurse = notes_nurse.merge(df1, how = 'inner',  left_on=\"HADM_ID\", right_on = \"HADM_ID\")\n",
    "df_phys = notes_phys.merge(df1, how = 'inner',  left_on=\"HADM_ID\", right_on = \"HADM_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rad_disch = df_all1.merge(df1, how = 'inner',  left_on=\"HADM_ID\", right_on = \"HADM_ID\")\n",
    "df_nurse_phys = df_all2.merge(df1, how = 'inner',  left_on=\"HADM_ID\", right_on = \"HADM_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rad.to_csv(os.path.join(files_dir, 'rad.csv'), index=False)\n",
    "df_disch.to_csv(os.path.join(files_dir, 'disch.csv'), index=False)\n",
    "df_nurse.to_csv(os.path.join(files_dir, 'nurse.csv'), index=False)\n",
    "df_phys.to_csv(os.path.join(files_dir, 'phys.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rad_disch.to_csv(os.path.join(files_dir, 'rad_disch.csv'), index=False)\n",
    "df_nurse_phys.to_csv(os.path.join(files_dir, 'nurse_phys.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAD: (45526, 6986)\n",
      "NURSE: (9070, 6986)\n",
      "DISCH: (52726, 6986)\n",
      "PHYS: (8983, 6986)\n"
     ]
    }
   ],
   "source": [
    "print(f'RAD: {df_rad.shape}\\nNURSE: {df_nurse.shape}\\nDISCH: {df_disch.shape}\\nPHYS: {df_phys.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.read_csv(os.path.join(files_dir, 'notes_rad.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001.0</td>\n",
       "      <td>chest pa lat clip reason eval infiltrate medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003.0</td>\n",
       "      <td>pm liver gallbladder us single organ clip reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006.0</td>\n",
       "      <td>chest portable ap clip reason please assess in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100009.0</td>\n",
       "      <td>pm chest pa lat clip reason pre op admitting d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100010.0</td>\n",
       "      <td>pm chest portable ap different physician reaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45521</th>\n",
       "      <td>199993.0</td>\n",
       "      <td>chest portable ap clip reason r effusion medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45522</th>\n",
       "      <td>199994.0</td>\n",
       "      <td>pm chest portable ap clip reason pt self extub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45523</th>\n",
       "      <td>199995.0</td>\n",
       "      <td>pm abdomen u complete study duplex dopp abd pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45524</th>\n",
       "      <td>199998.0</td>\n",
       "      <td>pm chest port line placement clip reason line ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45525</th>\n",
       "      <td>199999.0</td>\n",
       "      <td>chest portable ap clip reason interval change ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45526 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HADM_ID                                               TEXT\n",
       "0      100001.0  chest pa lat clip reason eval infiltrate medic...\n",
       "1      100003.0  pm liver gallbladder us single organ clip reas...\n",
       "2      100006.0  chest portable ap clip reason please assess in...\n",
       "3      100009.0  pm chest pa lat clip reason pre op admitting d...\n",
       "4      100010.0  pm chest portable ap different physician reaso...\n",
       "...         ...                                                ...\n",
       "45521  199993.0  chest portable ap clip reason r effusion medic...\n",
       "45522  199994.0  pm chest portable ap clip reason pt self extub...\n",
       "45523  199995.0  pm abdomen u complete study duplex dopp abd pe...\n",
       "45524  199998.0  pm chest port line placement clip reason line ...\n",
       "45525  199999.0  chest portable ap clip reason interval change ...\n",
       "\n",
       "[45526 rows x 2 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## Combine notes based on sim\n",
    "tf_matrix = tfidf.fit_transform(doc)\n",
    "scores = []\n",
    "short_kb = \"\"\n",
    "for i in range(kb_vec.shape[0]):\n",
    "        scores.append({'idx':i, 'sim': cosine_similarity(utt_vec, kb_vec[i])})\n",
    "    ref = heapq.nlargest(2, scores, key=lambda s: s['sim'])\n",
    "    del doc[0]\n",
    "    for i in ref:\n",
    "        short_kb += doc[i['idx']] + \". \"'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
